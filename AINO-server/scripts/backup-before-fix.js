#!/usr/bin/env node

/**
 * æ•°æ®å¤‡ä»½è„šæœ¬ - åœ¨ä¿®å¤æ•°æ®éš”ç¦»é—®é¢˜å‰å¤‡ä»½æ‰€æœ‰æ•°æ®
 */

import { db } from '../src/db/index.js'
import { sql } from 'drizzle-orm'
import fs from 'fs'
import path from 'path'

async function backupData() {
  console.log('ğŸ’¾ å¼€å§‹å¤‡ä»½æ•°æ®...')
  
  try {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
    const backupDir = path.join(process.cwd(), 'backups', timestamp)
    
    // åˆ›å»ºå¤‡ä»½ç›®å½•
    if (!fs.existsSync(backupDir)) {
      fs.mkdirSync(backupDir, { recursive: true })
    }
    
    console.log(`ğŸ“ å¤‡ä»½ç›®å½•: ${backupDir}`)
    
    // 1. å¤‡ä»½æ‰€æœ‰è®°å½•
    console.log('\nğŸ“Š å¤‡ä»½æ‰€æœ‰è®°å½•...')
    const allRecords = await db.execute(sql`
      SELECT 
        id, 
        tenant_id, 
        props,
        created_at,
        updated_at,
        deleted_at
      FROM dir_users 
      ORDER BY created_at DESC
    `)
    
    const recordsBackup = {
      timestamp: new Date().toISOString(),
      totalRecords: allRecords.rows.length,
      records: allRecords.rows
    }
    
    fs.writeFileSync(
      path.join(backupDir, 'records-backup.json'),
      JSON.stringify(recordsBackup, null, 2)
    )
    
    console.log(`âœ… å·²å¤‡ä»½ ${allRecords.rows.length} æ¡è®°å½•`)
    
    // 2. å¤‡ä»½ç›®å½•ä¿¡æ¯
    console.log('\nğŸ“ å¤‡ä»½ç›®å½•ä¿¡æ¯...')
    const directories = await db.execute(sql`
      SELECT 
        id,
        name,
        type,
        application_id,
        created_at,
        updated_at
      FROM directories 
      ORDER BY created_at DESC
    `)
    
    const dirsBackup = {
      timestamp: new Date().toISOString(),
      totalDirectories: directories.rows.length,
      directories: directories.rows
    }
    
    fs.writeFileSync(
      path.join(backupDir, 'directories-backup.json'),
      JSON.stringify(dirsBackup, null, 2)
    )
    
    console.log(`âœ… å·²å¤‡ä»½ ${directories.rows.length} ä¸ªç›®å½•`)
    
    // 3. å¤‡ä»½å­—æ®µå®šä¹‰
    console.log('\nğŸ”§ å¤‡ä»½å­—æ®µå®šä¹‰...')
    const fieldDefs = await db.execute(sql`
      SELECT 
        id,
        key,
        kind,
        type,
        directory_id,
        schema,
        relation,
        lookup,
        computed,
        validators,
        read_roles,
        write_roles,
        required
      FROM field_defs 
      ORDER BY id
    `)
    
    const fieldsBackup = {
      timestamp: new Date().toISOString(),
      totalFieldDefs: fieldDefs.rows.length,
      fieldDefs: fieldDefs.rows
    }
    
    fs.writeFileSync(
      path.join(backupDir, 'field-defs-backup.json'),
      JSON.stringify(fieldsBackup, null, 2)
    )
    
    console.log(`âœ… å·²å¤‡ä»½ ${fieldDefs.rows.length} ä¸ªå­—æ®µå®šä¹‰`)
    
    // 4. åˆ›å»ºå¤‡ä»½æ‘˜è¦
    const summary = {
      timestamp: new Date().toISOString(),
      backupLocation: backupDir,
      summary: {
        totalRecords: allRecords.rows.length,
        totalDirectories: directories.rows.length,
        totalFieldDefs: fieldDefs.rows.length
      },
      files: [
        'records-backup.json',
        'directories-backup.json',
        'field-defs-backup.json'
      ]
    }
    
    fs.writeFileSync(
      path.join(backupDir, 'backup-summary.json'),
      JSON.stringify(summary, null, 2)
    )
    
    console.log('\nğŸ‰ æ•°æ®å¤‡ä»½å®Œæˆï¼')
    console.log(`ğŸ“ å¤‡ä»½ä½ç½®: ${backupDir}`)
    console.log('ğŸ“„ å¤‡ä»½æ–‡ä»¶:')
    console.log('  - records-backup.json (æ‰€æœ‰è®°å½•)')
    console.log('  - directories-backup.json (ç›®å½•ä¿¡æ¯)')
    console.log('  - field-defs-backup.json (å­—æ®µå®šä¹‰)')
    console.log('  - backup-summary.json (å¤‡ä»½æ‘˜è¦)')
    
  } catch (error) {
    console.error('âŒ å¤‡ä»½å¤±è´¥:', error)
    process.exit(1)
  }
}

backupData()
